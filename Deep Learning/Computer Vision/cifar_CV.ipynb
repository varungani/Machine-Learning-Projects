{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jlq_rPdEf6ro",
    "outputId": "c8f5bd09-3837-4948-8dfd-85d22d090d60"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_6 (Conv2D)           (None, 32, 32, 32)        896       \n",
      "                                                                 \n",
      " max_pooling2d_6 (MaxPooling  (None, 16, 16, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_7 (Conv2D)           (None, 16, 16, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_7 (MaxPooling  (None, 8, 8, 64)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten_3 (Flatten)         (None, 4096)              0         \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 64)                262208    \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 10)                650       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 282,250\n",
      "Trainable params: 282,250\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/10\n",
      "1563/1563 [==============================] - 65s 41ms/step - loss: 1.3920 - accuracy: 0.5006 - val_loss: 1.1137 - val_accuracy: 0.6033\n",
      "Epoch 2/10\n",
      "1563/1563 [==============================] - 61s 39ms/step - loss: 1.0288 - accuracy: 0.6410 - val_loss: 1.0050 - val_accuracy: 0.6474\n",
      "Epoch 3/10\n",
      "1563/1563 [==============================] - 61s 39ms/step - loss: 0.9036 - accuracy: 0.6833 - val_loss: 0.9282 - val_accuracy: 0.6740\n",
      "Epoch 4/10\n",
      "1563/1563 [==============================] - 60s 39ms/step - loss: 0.8130 - accuracy: 0.7151 - val_loss: 1.0127 - val_accuracy: 0.6496\n",
      "Epoch 5/10\n",
      "1563/1563 [==============================] - 60s 39ms/step - loss: 0.7447 - accuracy: 0.7381 - val_loss: 0.8840 - val_accuracy: 0.6941\n",
      "Epoch 6/10\n",
      "1563/1563 [==============================] - 60s 39ms/step - loss: 0.6803 - accuracy: 0.7623 - val_loss: 0.9020 - val_accuracy: 0.6971\n",
      "Epoch 7/10\n",
      "1563/1563 [==============================] - 60s 38ms/step - loss: 0.6210 - accuracy: 0.7853 - val_loss: 0.9268 - val_accuracy: 0.6915\n",
      "Epoch 8/10\n",
      "1563/1563 [==============================] - 60s 39ms/step - loss: 0.5738 - accuracy: 0.7996 - val_loss: 0.9099 - val_accuracy: 0.6977\n",
      "Epoch 9/10\n",
      "1563/1563 [==============================] - 60s 38ms/step - loss: 0.5279 - accuracy: 0.8143 - val_loss: 0.9418 - val_accuracy: 0.7001\n",
      "Epoch 10/10\n",
      "1563/1563 [==============================] - 60s 38ms/step - loss: 0.4811 - accuracy: 0.8313 - val_loss: 0.9644 - val_accuracy: 0.6981\n",
      "313/313 [==============================] - 3s 10ms/step - loss: 0.9644 - accuracy: 0.6981\n",
      "0.6980999708175659\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "from keras import layers\n",
    "from keras.datasets import cifar10\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import os\n",
    "import random\n",
    "import glob\n",
    "import shutil\n",
    "from keras.optimizers import Adam\n",
    "from keras.layers import Activation,Dense,Flatten,BatchNormalization,Conv2D,MaxPool2D\n",
    "from keras.metrics import categorical_crossentropy\n",
    "import itertools\n",
    "tf.keras.datasets.cifar10.load_data()\n",
    "(x_train,y_train),(x_test,y_test)=keras.datasets.cifar10.load_data()\n",
    "\n",
    "\n",
    "\n",
    "trainimg=x_train.astype('float32')\n",
    "testimg=x_test.astype('float32')\n",
    "\n",
    "trainimg=trainimg/255.0\n",
    "testimg=testimg/255.0\n",
    "model=Sequential([\n",
    "    Conv2D(filters=32,kernel_size=(3,3),activation='relu',padding='same',input_shape=(32,32,3)),\n",
    "    MaxPool2D(pool_size=(2,2),strides=2),\n",
    "    Conv2D(filters=64,kernel_size=(3,3),activation='relu',padding='same'),\n",
    "    MaxPool2D(pool_size=(2,2),strides=2),\n",
    "    Flatten(),\n",
    "    Dense(64,activation='relu'),\n",
    "    Dense(units=10,activation='softmax'),\n",
    "])\n",
    "print(model.summary())\n",
    "model.compile(optimizer='Adam',loss='sparse_categorical_crossentropy',metrics=['accuracy'])\n",
    "model.fit(x=trainimg,y=y_train,epochs=10,verbose=1,validation_data=(testimg,y_test))\n",
    "test_loss, test_acc = model.evaluate(testimg,  y_test , verbose=1)\n",
    "print(test_acc)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
